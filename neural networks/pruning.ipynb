{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c75c07e-739f-4e9f-b627-622a4088a526",
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment to install\n",
    "#pip install -q tensorflow-model-optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dadb4629-d790-48e6-9cc8-2ac8d8e1a2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import tensorflow_model_optimization as tfmot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f8eaa3-a3e5-4181-839e-aa84d65f0c5c",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Not all the features in the model are equally contributing, and at the same time not all the weights are contributing to the model performance. so why we cannot get rid off?\n",
    "\n",
    "Sparse model are lighter to train and can be compressed, the weights equal to zero are not used in inference and thus the model is faster (which can be really importance if latency is an issue) without great loss of accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0060bdec-7f89-458f-b214-bb189178723f",
   "metadata": {},
   "source": [
    "## training a model without and with pruning\n",
    "\n",
    "\n",
    "we are using the classical MNIST to test. We will train a model and then prune after. \n",
    "We are using low magnitude pruning, this method is removing after each epoch the weights wwhich have the lower magnitude (a weight with low value is contributing less to the model, so we can theoretically eliminate without much harm to the model). Recall that a neuron if has a value of zero is not anymore contributing to the model. Therefore, low magnitude pruning is just setting the neuron with low weight value to zero (you use a lambda theresold). In general, this method allows to remove weight that are not contributing much without the risk to loose neuron that are important for the performance (i.e. here accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f31c4d2f-0063-49a2-a070-05b13d3b294f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1688/1688 [==============================] - 7s 4ms/step - loss: 0.3113 - accuracy: 0.9138 - val_loss: 0.1599 - val_accuracy: 0.9563\n",
      "Epoch 2/4\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.1491 - accuracy: 0.9569 - val_loss: 0.1103 - val_accuracy: 0.9702\n",
      "Epoch 3/4\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.1073 - accuracy: 0.9684 - val_loss: 0.0993 - val_accuracy: 0.9723\n",
      "Epoch 4/4\n",
      "1688/1688 [==============================] - 6s 4ms/step - loss: 0.0844 - accuracy: 0.9747 - val_loss: 0.0961 - val_accuracy: 0.9728\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd86c786110>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keras provides MNIST dataset\n",
    "mnist = keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# we normalize the input between 0 and 1\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# We use here a simple sequential architechture (but it works also with a CNN)\n",
    "model = keras.Sequential([\n",
    "  keras.layers.InputLayer(input_shape=(28, 28)),\n",
    "  keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
    "  keras.layers.Flatten(),\n",
    "  keras.layers.Dense(64, activation='relu'),\n",
    "  keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(\n",
    "  train_images,\n",
    "  train_labels,\n",
    "  epochs=4,\n",
    "  validation_split=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "060b5212-0b67-45a5-92ac-56068c88b1c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape (Reshape)            (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 50,890\n",
      "Trainable params: 50,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#number of parameter in the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db381ed8-fc3a-4df5-b4c4-5161431aca74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before pruning test accuracy: 0.9711999893188477\n",
      "Saved pre-pruned model to: /tmp/tmpsb71m2l0.h5\n"
     ]
    }
   ],
   "source": [
    "_, baseline_model_accuracy = model.evaluate(\n",
    "test_images, test_labels, verbose=0)\n",
    "\n",
    "print('before pruning test accuracy:', baseline_model_accuracy)\n",
    "\n",
    "#we are saving in the temporary file\n",
    "_, keras_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(model, keras_file, include_optimizer=False)\n",
    "print('Saved pre-pruned model to:', keras_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77ee9526-1fab-404b-9f6a-01a2536cf4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "prune_low_magnitude_reshape_ (None, 28, 28, 1)         1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_flatten_ (None, 784)               1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_dense_2  (None, 64)                100418    \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_dense_3  (None, 10)                1292      \n",
      "=================================================================\n",
      "Total params: 101,712\n",
      "Trainable params: 50,890\n",
      "Non-trainable params: 50,822\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "#you need this for pruning, is a wrapper to allow to prune our weights\n",
    "#we will use low magnitude pruning\n",
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "\n",
    "# we will do just two epochs\n",
    "batch_size = 128\n",
    "epochs = 2\n",
    "validation_split = 0.1 # 10% of training set will be used for validation set. \n",
    "\n",
    "num_images = train_images.shape[0] * (1 - validation_split)\n",
    "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
    "\n",
    "# we start inserting 50 % of sparsity, until 80%\n",
    "pruning_params = {\n",
    "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
    "                                                               final_sparsity=0.80,\n",
    "                                                               begin_step=0,\n",
    "                                                               end_step=end_step)\n",
    "}\n",
    "\n",
    "model_for_pruning = prune_low_magnitude(model, **pruning_params)\n",
    "\n",
    "# we need to recompile the file\n",
    "model_for_pruning.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_for_pruning.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2eaae5d-d611-4a82-bf02-612cf7cc263b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "  2/422 [..............................] - ETA: 23s - loss: 0.1117 - accuracy: 0.9688WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0048s vs `on_train_batch_end` time: 0.0126s). Check your callbacks.\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.1045 - accuracy: 0.9709 - val_loss: 0.1028 - val_accuracy: 0.9723\n",
      "Epoch 2/2\n",
      "422/422 [==============================] - 2s 6ms/step - loss: 0.0929 - accuracy: 0.9733 - val_loss: 0.0978 - val_accuracy: 0.9745\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd68ef13b50>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logdir = tempfile.mkdtemp()\n",
    "\n",
    "#updatepruningstep is necessary to propagate the optimizer activities\n",
    "callbacks = [\n",
    "  tfmot.sparsity.keras.UpdatePruningStep(), #necessary to call for the pruning\n",
    "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir), #saving info\n",
    "]\n",
    "\n",
    "model_for_pruning.fit(train_images, train_labels,\n",
    "                  batch_size=batch_size, epochs=epochs, validation_split=validation_split,\n",
    "                  callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d35a490c-008c-4aea-a706-fcde92951f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-pruning test accuracy: 0.9711999893188477\n",
      "post-pruning test accuracy: 0.9671000242233276\n"
     ]
    }
   ],
   "source": [
    "_, model_for_pruning_accuracy = model_for_pruning.evaluate(\n",
    "   test_images, test_labels, verbose=0)\n",
    "\n",
    "print('pre-pruning test accuracy:', baseline_model_accuracy) \n",
    "print('post-pruning test accuracy:', model_for_pruning_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbc3b3ee-a0da-445e-98b4-b6ef0a8e0ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Saved pruned Keras model to: /tmp/tmpnsgvfnva.h5\n"
     ]
    }
   ],
   "source": [
    "#strip pruning allow to make model dense after the pruning step\n",
    "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
    "\n",
    "_, pruned_keras_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n",
    "print('Saved pruned Keras model to:', pruned_keras_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
